{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f571fa9b",
   "metadata": {},
   "source": [
    "NLTK ile Tokenler\n",
    "\n",
    "sent_tokenize ===> Cümleleri tokenleştirme\n",
    "\n",
    "word_tokenize ==> Kelimeleri tokenleştirme\n",
    "\n",
    "* NLP projelerinde çoğunlukla kelimeler tokenleştirilir.\n",
    "\n",
    "* split metodu ile python da kelimeleri ayırabiliriz.\n",
    "\n",
    "* Bu metod ile cümle içindeki nokta - virgül gibi ifadelerde kelimeye dahil edildi. Bu çok hoş bir durum değil. \n",
    "\n",
    "* Kurallar içeren bir tokenleştirme kullanılır. (word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2133910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e7f86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" inci kabak 2003 yılında bursada doğmuştur, yemek yapmayı sevmektedir ve aslında çok akıllı bir insandır. Şu an devam ettiği stajı bitince hemen iş bulacağını düşünmektedir. Bir his ona bunu düşündürmektedir. Ama kendisi de bilmiyor bunu.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f199ec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inci',\n",
       " 'kabak',\n",
       " '2003',\n",
       " 'yılında',\n",
       " 'bursada',\n",
       " 'doğmuştur,',\n",
       " 'yemek',\n",
       " 'yapmayı',\n",
       " 'sevmektedir',\n",
       " 've',\n",
       " 'aslında',\n",
       " 'çok',\n",
       " 'akıllı',\n",
       " 'bir',\n",
       " 'insandır.',\n",
       " 'Şu',\n",
       " 'an',\n",
       " 'devam',\n",
       " 'ettiği',\n",
       " 'stajı',\n",
       " 'bitince',\n",
       " 'hemen',\n",
       " 'iş',\n",
       " 'bulacağını',\n",
       " 'düşünmektedir.',\n",
       " 'Bir',\n",
       " 'his',\n",
       " 'ona',\n",
       " 'bunu',\n",
       " 'düşündürmektedir.',\n",
       " 'Ama',\n",
       " 'kendisi',\n",
       " 'de',\n",
       " 'bilmiyor',\n",
       " 'bunu.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67535180",
   "metadata": {},
   "source": [
    "Punkt, cümleleri belirtmeye yarar.\n",
    "\n",
    "Örneğin: 2 kalemim var. Kitap okuyorum. \n",
    "\n",
    "2 ayrı cümle şeklinde ayırmaya yarar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a7de787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a6228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inci',\n",
       " 'kabak',\n",
       " '2003',\n",
       " 'yılında',\n",
       " 'bursada',\n",
       " 'doğmuştur',\n",
       " ',',\n",
       " 'yemek',\n",
       " 'yapmayı',\n",
       " 'sevmektedir',\n",
       " 've',\n",
       " 'aslında',\n",
       " 'çok',\n",
       " 'akıllı',\n",
       " 'bir',\n",
       " 'insandır',\n",
       " '.',\n",
       " 'Şu',\n",
       " 'an',\n",
       " 'devam',\n",
       " 'ettiği',\n",
       " 'stajı',\n",
       " 'bitince',\n",
       " 'hemen',\n",
       " 'iş',\n",
       " 'bulacağını',\n",
       " 'düşünmektedir',\n",
       " '.',\n",
       " 'Bir',\n",
       " 'his',\n",
       " 'ona',\n",
       " 'bunu',\n",
       " 'düşündürmektedir',\n",
       " '.',\n",
       " 'Ama',\n",
       " 'kendisi',\n",
       " 'de',\n",
       " 'bilmiyor',\n",
       " 'bunu',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31e0a61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' inci kabak 2003 yılında bursada doğmuştur, yemek yapmayı sevmektedir ve aslında çok akıllı bir insandır.',\n",
       " 'Şu an devam ettiği stajı bitince hemen iş bulacağını düşünmektedir.',\n",
       " 'Bir his ona bunu düşündürmektedir.',\n",
       " 'Ama kendisi de bilmiyor bunu.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8ec740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inci\n",
      "kabak\n",
      "2003\n",
      "yılında\n",
      "bursada\n",
      "doğmuştur\n",
      ",\n",
      "yemek\n",
      "yapmayı\n",
      "sevmektedir\n",
      "ve\n",
      "aslında\n",
      "çok\n",
      "akıllı\n",
      "bir\n",
      "insandır\n",
      ".\n",
      "Şu\n",
      "an\n",
      "devam\n",
      "ettiği\n",
      "stajı\n",
      "bitince\n",
      "hemen\n",
      "iş\n",
      "bulacağını\n",
      "düşünmektedir\n",
      ".\n",
      "Bir\n",
      "his\n",
      "ona\n",
      "bunu\n",
      "düşündürmektedir\n",
      ".\n",
      "Ama\n",
      "kendisi\n",
      "de\n",
      "bilmiyor\n",
      "bunu\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in word_tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa93a7",
   "metadata": {},
   "source": [
    "NLTK ile Stop Words\n",
    "* Veri analizi yaparken anlam ifade etmeyen kelimelerdir. Gereksiz kelimeler.\n",
    "* İngilizcedeki (-a, -an, the gibi kelimeler)\n",
    "* İngilizcedeki stopwords ifadeler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ec86f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cc5267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Sarah says i am the king for a kitchen a may wooden bear kitchen eat an apple\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0696a",
   "metadata": {},
   "source": [
    "Stopwords :\n",
    "\n",
    "Cümle içinde anlamı olmayan kelimelerdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf55fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ece664d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acaba',\n",
       " 'ama',\n",
       " 'aslında',\n",
       " 'az',\n",
       " 'bazı',\n",
       " 'belki',\n",
       " 'biri',\n",
       " 'birkaç',\n",
       " 'birşey',\n",
       " 'biz',\n",
       " 'bu',\n",
       " 'çok',\n",
       " 'çünkü',\n",
       " 'da',\n",
       " 'daha',\n",
       " 'de',\n",
       " 'defa',\n",
       " 'diye',\n",
       " 'eğer',\n",
       " 'en',\n",
       " 'gibi',\n",
       " 'hem',\n",
       " 'hep',\n",
       " 'hepsi',\n",
       " 'her',\n",
       " 'hiç',\n",
       " 'için',\n",
       " 'ile',\n",
       " 'ise',\n",
       " 'kez',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'mı',\n",
       " 'mu',\n",
       " 'mü',\n",
       " 'nasıl',\n",
       " 'ne',\n",
       " 'neden',\n",
       " 'nerde',\n",
       " 'nerede',\n",
       " 'nereye',\n",
       " 'niçin',\n",
       " 'niye',\n",
       " 'o',\n",
       " 'sanki',\n",
       " 'şey',\n",
       " 'siz',\n",
       " 'şu',\n",
       " 'tüm',\n",
       " 've',\n",
       " 'veya',\n",
       " 'ya',\n",
       " 'yani']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"turkish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac7c5c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words(\"english\")   stopwords.words(\"turkish\")\n",
    "stopwords = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed60f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e0189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "\n",
    "for word in words:\n",
    "    if word not in stopwords:\n",
    "        filtered_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ded765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inci',\n",
       " 'kabak',\n",
       " '2003',\n",
       " 'yılında',\n",
       " 'bursada',\n",
       " 'doğmuştur',\n",
       " ',',\n",
       " 'yemek',\n",
       " 'yapmayı',\n",
       " 'sevmektedir',\n",
       " 'aslında',\n",
       " 'çok',\n",
       " 'akıllı',\n",
       " 'bir',\n",
       " 'insandır',\n",
       " '.',\n",
       " 'Şu',\n",
       " 'devam',\n",
       " 'ettiği',\n",
       " 'stajı',\n",
       " 'bitince',\n",
       " 'hemen',\n",
       " 'iş',\n",
       " 'bulacağını',\n",
       " 'düşünmektedir',\n",
       " '.',\n",
       " 'Bir',\n",
       " 'ona',\n",
       " 'bunu',\n",
       " 'düşündürmektedir',\n",
       " '.',\n",
       " 'Ama',\n",
       " 'kendisi',\n",
       " 'de',\n",
       " 'bilmiyor',\n",
       " 'bunu',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70616a",
   "metadata": {},
   "source": [
    "NLTK ile Stemming\n",
    "\n",
    "* Bir kelimenin kökünü almak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94ce110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef19fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ce5bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"drive\", \"driving\", \"drives\", \"drove\", \"cats\", \"children\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bbbb144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\n",
      "drive\n",
      "drive\n",
      "drove\n",
      "cat\n",
      "children\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672106e",
   "metadata": {},
   "source": [
    "NLTK ile Part of Speech Tagging (NLTK ile cümlenin ögeleri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022c61d",
   "metadata": {},
   "source": [
    "Kitap: İsim (Noun - NN)\n",
    "\n",
    "okumak: Fiil (Verb - VB)\n",
    "\n",
    "keyifli: Sıfat (Adjective - JJ)\n",
    "\n",
    "bir: Belirteç / Artikel (Determiner - DT)\n",
    "\n",
    "eylemdir: İsim (Noun - NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88ef6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eece7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"inci kabak ve bu durum ile ilgili bir sorun mu var acaba diye düşünüyorum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd368bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9dc5ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inci', 'NN'),\n",
       " ('kabak', 'NN'),\n",
       " ('ve', 'NN'),\n",
       " ('bu', 'NN'),\n",
       " ('durum', 'NN'),\n",
       " ('ile', 'NN'),\n",
       " ('ilgili', 'NN'),\n",
       " ('bir', 'NN'),\n",
       " ('sorun', 'NN'),\n",
       " ('mu', 'NN'),\n",
       " ('var', 'NN'),\n",
       " ('acaba', 'NN'),\n",
       " ('diye', 'NN'),\n",
       " ('düşünüyorum', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b804da",
   "metadata": {},
   "source": [
    "Named Entity Recognition\n",
    "\n",
    "Metindeki kuruluşlar, yerler, kişiler bulunabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b2ab55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Kalem ve kitap dökümanlarını anlayamadım. Bugün hava çok sıcak değil ve poğaça yedim.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b25378de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96dddb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04098d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55b27d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77875cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_ent = nltk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f160094",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_ent.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6b90e",
   "metadata": {},
   "source": [
    "-----TURLER-----\n",
    "ORGANIZATION   \n",
    "PERSON\n",
    "LOCATION\n",
    "DATE\n",
    "TIME\n",
    "MONEY\n",
    "PERCENT\n",
    "FACILITY\n",
    "GPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0cf42",
   "metadata": {},
   "source": [
    "LEMMATİZİNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db94f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aae931d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d598de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "893d639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"drive\", \"driving\", \"driver\", \"drives\", \"drove\", \"cats\", \"children\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "083a2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\n",
      "driving\n",
      "driver\n",
      "drive\n",
      "drove\n",
      "cat\n",
      "child\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(lem.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265a006",
   "metadata": {},
   "source": [
    "CORPUS - CORPARA\n",
    "\n",
    "Corpus : Doğal dil işleme içerisinde kullandığımız metin.\n",
    "\n",
    "Corpara : Corpus'un çoğulu.\n",
    "\n",
    "Corpus örnekleri: Bir yazarın kitapları, Wikipedia, bir sitedeki yazılar, metin olan her şey.\n",
    "\n",
    "\n",
    "* Kaggle, Gutenberg (telif hakları geçmiş kitaplar), wikipedia, Common Crawl (websitesi arşivleme sitesi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bc7fb",
   "metadata": {},
   "source": [
    "# BÖLÜM 4 : Kelime Vektörleri: word2vec \n",
    "\n",
    "* Bilgisayarların dilimizi anlaması için ilk adım kelimeleri anlamasını sağlamaktır.\n",
    "\n",
    "## Kelimelerin Temsil Edilmesi :\n",
    "* Kelimeleri one-hot vektör olarak temsil edebiliriz.\n",
    "* Kelime sayısıyla vektörlerin boyutu da artacaktır.\n",
    "* 10 bin kelime için 10 bin uzunluğunda vektörler gerekir. \n",
    "\n",
    "* One-hot vektörler ile kelimeler arasındaki ilişki saklanmıyor.\n",
    "\n",
    "\n",
    "\n",
    "## Kelime Vektörleri :\n",
    "* Her kelime için birer vektör oluşturacağız.\n",
    "* Vektörler kelimeler arasındaki anlamsal bilgileri saklayacak.\n",
    "* Birbirine benzer kelimelerin vektörleri birbirine yakın olacak.\n",
    "* Kelime vektörü oluşturmak için en modern yöntemler : word2vec, GloVe.\n",
    "    \n",
    "    \n",
    "\n",
    "#### NOT : Kelime vektörü, word vector, word embedding hep aynı şeyi ifade ediyor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22837a89",
   "metadata": {},
   "source": [
    "### Kelimelerin Birbiriyle Bağı\n",
    "\n",
    "- Kelimenin etrafındaki diğer kelimeler o kelimeyi temsil eder.\n",
    "\n",
    "- İnsanlar kelimenin anlamını bilmese bile kelimenin cümle içerisindeki kullanımına göre anlam çıkartabiliriz.\n",
    "\n",
    "- Oluşturacağımız model bir kelimenin etrafındaki kelimelerden anlamlar çıkarabilirse o kelimeyi anlamaya yaklaşacaktır. \n",
    "\n",
    "1. Word2vec\n",
    "\n",
    "* Kenardaki kelimeler ortadaki kelimeyi temsil eder. \n",
    "\n",
    "\n",
    "#### Word2vec Algoritmaları\n",
    "\n",
    "\n",
    "* Skip-gram \n",
    "Ortadaki kelimelerden kenardaki kelimeleri tahmin eder.\n",
    "\n",
    "* Continuous bag of words (CBOW)\n",
    "Kenardaki kelimelerden ortadaki kelimeyi tahmin eder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344619a",
   "metadata": {},
   "source": [
    "### Skip-gram\n",
    "- Ortadaki kelimeye göre kenardaki kelimeler tahmin ediliyor. \n",
    "- Input: orta kelime, output: kenardaki kelimeler\n",
    "- Ortadaki kelimenin sağından ve solundan pencere büyüklüğü kadar kelime tahmin ediliyor.\n",
    "- Pencere büyüklüğü 2 ise sağdan 2 kelime ve soldan 2 kelime dikkate alınır.\n",
    "\n",
    "### CBOW\n",
    "- Kenardaki kelimelere göre orta kelime tahmin ediliyor.\n",
    "- Input: kenardaki kelimeler, ouput: orta kelime\n",
    "\n",
    "Skip-gram                                                   \n",
    "* Cbow'a göre küçük corpus'ta daha iyi sonuç verir.          \n",
    "* Nadir kelimeler daha iyi temsil edilir.\n",
    "* Cbow'a göre daha yavaş.\n",
    "\n",
    "- Her kelimenin 2 tane vektörü vardır. Vektörlerin bir tanesi o kelime ortadayken, diğeri o kelime kenardayken kullanılır.\n",
    "\n",
    "Cbow\n",
    "* Eğitim daha hızlı\n",
    "* Sık kullanılan kelimeleri daha iyi temsil eder.\n",
    "* Daha büyük corpus'a ihtiyaç duyar ve nadir kelimeleri temsil etmekte sıkıntı yaşayabilir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3636ea1",
   "metadata": {},
   "source": [
    "### Negative Sampling \n",
    "\n",
    "- Softmax hesaplamak bilgisayar için yavaş olacak\n",
    "\n",
    "- Hesaplamayı hızlandırmak için negatve sampling kullanacağız.\n",
    "\n",
    "* Kenardaki kelimelerin ortadaki kelime ile bulunma olasılığını artır, ortadaki kelime ile rastgele kelimelerin geçme olasılığını düşür. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a274df4",
   "metadata": {},
   "source": [
    "### Gensim ile word2vec \n",
    "\n",
    "- word2vec modelini eğitmek için Gensim kütüphanesini kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ea4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a52a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"hurriyet.txt\", \"r\", encoding=\"utf8\")\n",
    "text = f.read()\n",
    "t_list = text.split(\"\\n\")\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for cumle in t_list:\n",
    "    corpus.append(cumle.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18628272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['iran', 'devlet', 'televizyonu', 'ülkedeki', 'eyaletin', 'sinde', 'yapılan', 'reformcuları', 'protesto', 'amaçlı', 'yürüyüşlere', 'milyonlarca', 'kişinin', 'katıldığını', 'bildirdi'], ['gösterilerde', 'fitnecilere', 'ölüm', 'münafıklara', 'ölüm', 'abd', 'ye', 'ölüm', 'ingiltere', 'ye', 'ölüm', 'sloganları', 'atıldı'], ['dini', 'lider', 'ali', 'hamaney', 've', 'cumhurbaşkanı', 'mahmud', 'ahmedinejad', 'ı', 'destekleyen', 'iranlılar', 'son', 'olaylarda', 'yeğeni', 'öldürülen', 'mir', 'hüseyin', 'musevi', 'başta', 'olmak', 'üzere', 'muhalefet', 'liderlerini', 'kınadılar'], ['musevi', 'ye', 'ölüm', 've', 'idam', 'idam', 'sloganları', 'duyuldu'], ['muhalefet', 'liderleri', 'kaçtı', 'mı', 'aşure', 'günü', 'yaşanan', 'çatışmalarda', 'devlet', 'kaynaklarına', 'göre', 'u', 'terörist', 'olmak', 'üzere', 'kişi', 'ölmüştü'], ['den', 'fazla', 'kişinin', 'yaralandığı', 'olaylar', 'sırasında', 'en', 'az', 'kişi', 'tutuklanmıştı'], ['öte', 'yandan', 'iran', 'haber', 'ajansı', 'irna', 'muhalif', 'liderler', 'mir', 'hüseyin', 'musevi', 've', 'mehdi', 'kerrubi', 'nin', 'başkentten', 'kaçarak', 'ülkenin', 'kuzeyine', 'geçtiğini', 'ileri', 'sürdü', 'ancak', 'muhalefet', 'iddiayı', 'yalanladı'], ['hamaney', 'in', 'bir', 'dönem', 'korumalığını', 'yapan', 've', 'şu', 'anda', 'fransa', 'da', 'saklandığı', 'söylenen', 'bir', 'kişinin', 'muhalefete', 'verdiği', 'bilgilere', 'göre', 'münzevi', 'yaşamı', 'na', 'rağmen', 'dini', 'liderin', 'havyara', 'karşı', 'korkunç', 'bir', 'iştahı', 'var'], ['baston', 've', 'at', 'meraklısı', 'hamaney', 'aynı', 'zamanda', 'değerli', 'mücevherlerle', 'bezenmiş', 'bastonların', 've', 'cins', 'atların', 'koleksiyonunu', 'yapıyor'], ['hamaney', 'in', 'antika', 'bastonlarının', 'sayısı']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55211490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, vector_size=100, window=5, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c377119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11441805, -0.517762  , -0.32883212,  0.16788724,  0.4736586 ,\n",
       "       -0.12324828, -0.18891563,  0.71709245, -0.11172449, -0.28824493,\n",
       "        0.18180686, -0.28151736, -0.28410986,  0.31766108, -0.27903175,\n",
       "        0.2154665 ,  0.23174687, -0.6375721 ,  0.40225962, -0.62244093,\n",
       "       -0.02670325,  0.22198784,  0.4214316 , -0.3272247 , -0.06486432,\n",
       "        0.06787653, -0.18501188, -0.11086816, -0.05150787,  0.67891026,\n",
       "        0.28805366,  0.09954923, -0.11997108, -0.4608022 ,  0.35015643,\n",
       "       -0.2042699 , -0.23044303, -0.1929086 , -0.10749829, -0.42057377,\n",
       "        0.64558935, -0.17342427,  0.48789698, -0.43684456,  0.5910334 ,\n",
       "        0.40067247, -0.47784084,  0.0162584 , -0.02673133, -0.24007204,\n",
       "        0.07330141, -0.4792328 ,  0.31821278, -0.22353528, -0.25696513,\n",
       "       -0.2792269 ,  0.00408257,  0.18270163, -0.3563794 , -0.6462579 ,\n",
       "        0.01352152, -0.02135145, -0.17229545,  0.17328133, -0.3023181 ,\n",
       "       -0.05807097,  0.3657326 ,  0.0091391 , -0.27161613, -0.09259953,\n",
       "       -0.34035772, -0.08132342,  0.26015615, -0.2975576 ,  0.32201874,\n",
       "        0.18746027,  0.17490835, -0.14648093, -0.12278011, -0.2887461 ,\n",
       "        0.3649193 , -0.8321991 ,  0.1547067 ,  0.6340998 ,  0.36599907,\n",
       "       -0.03021613,  0.53181416,  0.7269382 ,  0.8053373 ,  0.46713388,\n",
       "        0.5200475 ,  0.12488283,  0.49917543,  0.10131984,  0.5431642 ,\n",
       "       -0.03041754,  0.02611975,  0.12469376,  0.01753526,  0.0111108 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"ankara\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ef41878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('danimarka', 0.8155601620674133),\n",
       " ('belçika', 0.8036590814590454),\n",
       " ('avusturya', 0.7988684177398682),\n",
       " ('almanya', 0.7712513208389282),\n",
       " ('kanada', 0.7324227690696716),\n",
       " ('ispanya', 0.730089545249939),\n",
       " ('finlandiya', 0.7283834218978882),\n",
       " ('italya', 0.7126741409301758),\n",
       " ('fransa', 0.7076416015625),\n",
       " ('letonya', 0.7063489556312561)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"hollanda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d6e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twitter', 0.7575631141662598),\n",
       " ('paylaşım', 0.7460806369781494),\n",
       " ('facebook', 0.7306453585624695),\n",
       " ('whatsapp', 0.7208570241928101),\n",
       " ('video', 0.7115055322647095),\n",
       " ('internete', 0.7110846042633057),\n",
       " ('twıtter', 0.703890323638916),\n",
       " ('sitelerine', 0.6983864903450012),\n",
       " ('sayfasına', 0.6965360045433044),\n",
       " ('internette', 0.6834545731544495)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"youtube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf113b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")  # modeli kaydetmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481eb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")    # kaydedilen modeli sonra yüklemek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9215cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestwords_tsneplot(model, word):\n",
    "    word_vectors = np.empty((0,100))\n",
    "    word_labels = [word]\n",
    "    \n",
    "    close_words = model.wv.most_similar(word)\n",
    "    \n",
    "    word_vectors = np.append(word_vectors, np.array([model.wv[word]]), axis = 0)\n",
    "    \n",
    "    \n",
    "    for w, _ in close_words:\n",
    "        word_labels.append(w)\n",
    "        word_vectors = np.append(word_vectors, np.array([model.wv[w]]), axis = 0)\n",
    "    \n",
    "    if n_samples <= 1:\n",
    "        print(f\"Hata: TSNE için yeterli örneklem yok ({n_samples} adet). En az 2 örneklem gereklidir.\")\n",
    "        return\n",
    "    elif n_samples <= 5: # Çok az örneklem varsa, perplexity'i n_samples - 1 olarak ayarlayın\n",
    "        perplexity_value = n_samples - 1\n",
    "    else: # Daha fazla örneklem varsa, varsayılan 30'u veya n_samples - 1'den küçük olanı seçin\n",
    "        perplexity_value = min(30, n_samples - 1)\n",
    "    \n",
    "    tsne = TSNE(random_state = 0)\n",
    "    Y = tsne.fit_transform(word_vectors)\n",
    "    \n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    \n",
    "    plt.scatter(x_coords, y_coords)\n",
    "    \n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5,-2), textcoords=\"offset points\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efe305c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m closestwords_tsneplot(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mberlin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m, in \u001b[0;36mclosestwords_tsneplot\u001b[1;34m(model, word)\u001b[0m\n\u001b[0;32m     11\u001b[0m     word_labels\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[0;32m     12\u001b[0m     word_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(word_vectors, np\u001b[38;5;241m.\u001b[39marray([model\u001b[38;5;241m.\u001b[39mwv[w]]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHata: TSNE için yeterli örneklem yok (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m adet). En az 2 örneklem gereklidir.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_samples' is not defined"
     ]
    }
   ],
   "source": [
    "closestwords_tsneplot(model, \"berlin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9f932",
   "metadata": {},
   "source": [
    "### Kelime Vektörleri : GloVe\n",
    "\n",
    "#### Word2Vec Özeti:\n",
    "- Corpus içindeki tüm kelimelerin üzerinden geç.\n",
    "\n",
    "- Her kelimenin etrafındaki kelimeleri tahmin et.\n",
    "\n",
    "- Bu yapıldığı zaman 2 kelime birbiriyle ne kadar sık bulunuyor vektöre yansıtılmış oluyor.\n",
    "\n",
    "- O halde neden sadece yanyana bulunan kelimeleri saymayalım ? \n",
    "\n",
    "\n",
    "#### Kelime Sayma:\n",
    "\n",
    "-Bir kelime diğer hangi kelimelerin yanında bulunuyor sayıp bir matrise dönüştürebiliriz.\n",
    "\n",
    "-2 seçenek: Pencere ve Full Doküman\n",
    "\n",
    "* Pencere : word2vec'e benzer. Kelimenin etrafında pencere oluştur ve kelimeleri say.\n",
    "\n",
    "* Doküman: Dokümanlar içerisinde geçen kelimeleri sayarak dökümanlar hakkında genel bir fikir edinebiliriz. (Latent semantic analysis)\n",
    "\n",
    "\n",
    "#### Sayma yöntemi ile ilgili problemler:\n",
    "* Kelime arttıkça boyutta artıyor.\n",
    "* Boyutu çok büyük olduğu için çok fazla hafızaya ihtiyacı var. \n",
    "\n",
    "#### Çözüm:\n",
    "* Önemli bilgilerin çoğunu belirli boyuttaki küçük bir vektöre sakla.\n",
    "* Vektöler genelde 25-1000 boyutlu.\n",
    "\n",
    "\n",
    "- Tekil Değer Anlayışı (Singular Value Decomposition)\n",
    "\n",
    "#### 1-) Kelime sayma vektörleri\n",
    " Global Vectors for Word Representation (GloVe)\n",
    " \n",
    "- Word2Vec'e alternatif olarak kullanılır.\n",
    "\n",
    "#### 2-) GloVe\n",
    "\n",
    "#### SVD'nin Karşılaştığı Problemler\n",
    "\n",
    "* Matris büyüdükçe bilgisauar yükü çok fazla büyüyor.\n",
    "* Yeni kelime veya döküman eklemek zor\n",
    "* Derin öğrenmeden faydalanmıyor.\n",
    "\n",
    "\n",
    "#### A. SAYMA TABANLI METODLAR \n",
    "* LSA, HAL \n",
    "* COALS, Hellinger-PCA\n",
    "\n",
    "* Hızlı eğitim.\n",
    "* Öncelikle kelime benzerliği yakalamaya çalışıyor.\n",
    "* Fazla sayıdaki kelimelere gereksiz önem veriliyor.\n",
    "\n",
    "#### B. TAHMİN METODLARI\n",
    "* Skip-gram / CBOW\n",
    "* NNLM, HLBL, RNN\n",
    "\n",
    "* Corpus büyüklüğüne göre yavaş olabiliyor. \n",
    "* İstatistiği efektif kullanmıyor. \n",
    "\n",
    "* Kelime benzerliği dışında kompleks bağlantıları da yakalayabiliyor.\n",
    "\n",
    "* Farklı problemlerde başarılı sonuçlar veriyor.\n",
    "\n",
    "#### Global Vectors (GloVe)\n",
    "- Hızlı eğitim \n",
    "- Çok büyük corpuslarda da kullanılabilir. \n",
    "- Küçük corpuslarda ve küçük vektörde iyi performans veriyor. \n",
    "\n",
    "* Skip-gram metni kelime kelime geziyor. 2 kelimenin ne kadar sık birbiriyle yan yana geldiğini hesaplar.\n",
    "\n",
    "* GloVe ise 2 kelimenin ne kadar sık yan yana olduğunun istatistiğini çıkartır.\n",
    "\n",
    "* word2vec te kelime kelime gezerken aynı zamanda optimizasyon da yapıyor. \n",
    "\n",
    "#### 3-) Gensim ile GloVe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a17098d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e4f2eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_408\\3465424922.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input, word2vec_output)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m glove_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove.6B.100d.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m word2vec_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglove.6B.100d.word2vec\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m glove2word2vec(glove_input, word2vec_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\utils.py:1522\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_func1\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1517\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1518\u001b[0m         fmt\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, reason\u001b[38;5;241m=\u001b[39mreason),\n\u001b[0;32m   1519\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1520\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1521\u001b[0m     )\n\u001b[1;32m-> 1522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\scripts\\glove2word2vec.py:109\u001b[0m, in \u001b[0;36mglove2word2vec\u001b[1;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglove2word2vec\u001b[39m(glove_input_file, word2vec_output_file):\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert `glove_input_file` in GloVe format to word2vec format and write it to `word2vec_output_file`.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     glovekv \u001b[38;5;241m=\u001b[39m KeyedVectors\u001b[38;5;241m.\u001b[39mload_word2vec_format(glove_input_file, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    111\u001b[0m     num_lines, num_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(glovekv), glovekv\u001b[38;5;241m.\u001b[39mvector_size\n\u001b[0;32m    112\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m vectors from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, num_lines, glove_input_file, word2vec_output_file)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39mfvocab, binary\u001b[38;5;241m=\u001b[39mbinary, encoding\u001b[38;5;241m=\u001b[39mencoding, unicode_errors\u001b[38;5;241m=\u001b[39municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit, datatype\u001b[38;5;241m=\u001b[39mdatatype, no_header\u001b[38;5;241m=\u001b[39mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2048\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2045\u001b[0m             counts[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(count)\n\u001b[0;32m   2047\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading projection weights from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n\u001b[1;32m-> 2048\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m   2049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_header:\n\u001b[0;32m   2050\u001b[0m         \u001b[38;5;66;03m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\smart_open\\smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 188\u001b[0m fobj \u001b[38;5;241m=\u001b[39m _shortcut_open(\n\u001b[0;32m    189\u001b[0m     uri,\n\u001b[0;32m    190\u001b[0m     mode,\n\u001b[0;32m    191\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    192\u001b[0m     buffering\u001b[38;5;241m=\u001b[39mbuffering,\n\u001b[0;32m    193\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    194\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    195\u001b[0m     newline\u001b[38;5;241m=\u001b[39mnewline,\n\u001b[0;32m    196\u001b[0m )\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\smart_open\\smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    359\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[1;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[38;5;241m=\u001b[39mbuffering, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
     ]
    }
   ],
   "source": [
    "glove_input = \"glove.6B.100d.txt\"\n",
    "word2vec_output = \"glove.6B.100d.word2vec\"\n",
    "glove2word2vec(glove_input, word2vec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96222b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_output, binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"istanbul\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"nietzsche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55085411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# king - man + woman = queen \n",
    "\n",
    "\n",
    "model.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"bangkok\", \"germany\"], negative=[\"berlin\"], topn=1)\n",
    "\n",
    "\n",
    "# thailand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"teach\", \"doctor\"], negative=[\"treat\"], topn=1)\n",
    "\n",
    "\n",
    "\n",
    "#teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cca354",
   "metadata": {},
   "source": [
    "## RNN\n",
    "### Farklı RNN Mimarileri\n",
    "-one to one\n",
    "-one to many >>>>>> Verilen resime açıklama yazmak\n",
    "-many to one >>>>>> Yorumun olumlu mu olumsuz mu olduğunu açıklamak\n",
    "-many to many >>>>>> Translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7578631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55292e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e9578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913b9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ecaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb3980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39e63513",
   "metadata": {},
   "source": [
    "### HepsiBurada uygulamasındaki 4 ve 5 yıldızlı yorumlara 1, 1 ve 2 yıldızlı yorumlara 0 verdik. Ayrıca 3 yıldızlı yorumları sildik. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96bbbaa",
   "metadata": {},
   "source": [
    "## SENTİMENT ANALYSİS\n",
    "\n",
    "### SA:Modelin Yapısı ve Verileri Yükleme\n",
    "\n",
    "       Text     (\"Bu ürün hiç iyi değil\")\n",
    "     Tokenizer  Text'i integer tokenlere çevir.\n",
    "     Embedding  Int tokenler için vektör oluştur.(Kelime vektörü)\n",
    "        RNN     Ardışık halde olan input u işle\n",
    "      Sigmoid   Olumlu veya olumsuz diye tahmin et \n",
    "-negative (0.0) -positive (1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b35ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7562d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding # CuDNNGRU'yu ayrıca yazmaya gerek yok\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9039da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"hepsiburada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4166d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3 yıldır tık demedi. :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3 yıldır kullanıyorum müthiş</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ürün bugün elime geçti çok fazla inceleme fırs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Almaya karar verdim. Hemencecik geldi. Keyifle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Günlük kullanımınızı çok çok iyi karsılıyor kı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243492</th>\n",
       "      <td>1</td>\n",
       "      <td>fiyatına göre güzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243493</th>\n",
       "      <td>1</td>\n",
       "      <td>Ürün kullanışlı iş görüyor fazlasıyla eşime al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243494</th>\n",
       "      <td>1</td>\n",
       "      <td>Hızlı Kargo, güzel ürün</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243495</th>\n",
       "      <td>1</td>\n",
       "      <td>telefon başarılı hızlı bir cihaz  sadece beyaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243496</th>\n",
       "      <td>1</td>\n",
       "      <td>Urun cok guzel pazar gunu siparis verdim adana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating                                             Review\n",
       "0            1                            3 yıldır tık demedi. :)\n",
       "1            1                      3 yıldır kullanıyorum müthiş \n",
       "2            1  Ürün bugün elime geçti çok fazla inceleme fırs...\n",
       "3            1  Almaya karar verdim. Hemencecik geldi. Keyifle...\n",
       "4            1  Günlük kullanımınızı çok çok iyi karsılıyor kı...\n",
       "...        ...                                                ...\n",
       "243492       1                                fiyatına göre güzel\n",
       "243493       1  Ürün kullanışlı iş görüyor fazlasıyla eşime al...\n",
       "243494       1                            Hızlı Kargo, güzel ürün\n",
       "243495       1  telefon başarılı hızlı bir cihaz  sadece beyaz...\n",
       "243496       1  Urun cok guzel pazar gunu siparis verdim adana...\n",
       "\n",
       "[243497 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d64d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"Rating\"].values.tolist()\n",
    "data = dataset[\"Review\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523bfb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(len(data) * 0.80)\n",
    "x_train, x_test = data[:cutoff], data[cutoff:]\n",
    "y_train, y_test = target[:cutoff], data[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325b4ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ürün sipariş verdim 2 gün içinde elime ulaştı her zaman ki gibi kullanışlı bi ürün daha once de bu mouse dan almıştım.bu yüzden tereddütsüz aldım . alacak olanlara öneririm'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5b1592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ürünü alalı 3 hafta kadar oldu. aralıksız kullanıyorum bilgisyarım sürekli açık durur ve ben günde yaklaşık 12 saat başındayım mousesu çok kullanırım. şimdiye kadar bir problem yaşamadım ve çok memnunum almak isteyenlere tavsiye ederim.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f02793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[800]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef60de",
   "metadata": {},
   "source": [
    "### SA : Tokenleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "495f5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c790af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd9e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'çok': 1,\n",
       " 'bir': 2,\n",
       " 've': 3,\n",
       " 'ürün': 4,\n",
       " 'bu': 5,\n",
       " 'iyi': 6,\n",
       " 'güzel': 7,\n",
       " 'için': 8,\n",
       " 'tavsiye': 9,\n",
       " 'ederim': 10,\n",
       " 'daha': 11,\n",
       " 'ama': 12,\n",
       " 'da': 13,\n",
       " 'gayet': 14,\n",
       " 'hızlı': 15,\n",
       " 'teşekkürler': 16,\n",
       " 'aldım': 17,\n",
       " 'de': 18,\n",
       " 'ürünü': 19,\n",
       " 'gibi': 20,\n",
       " 'yok': 21,\n",
       " 'uygun': 22,\n",
       " 'olarak': 23,\n",
       " 'kaliteli': 24,\n",
       " 'en': 25,\n",
       " '2': 26,\n",
       " 'kargo': 27,\n",
       " 'fiyat': 28,\n",
       " 'elime': 29,\n",
       " 'kadar': 30,\n",
       " 'ile': 31,\n",
       " 'göre': 32,\n",
       " 'geldi': 33,\n",
       " 'var': 34,\n",
       " 'hepsiburada': 35,\n",
       " 'ben': 36,\n",
       " 'gerçekten': 37,\n",
       " '1': 38,\n",
       " 'fiyata': 39,\n",
       " 'gün': 40,\n",
       " 'sonra': 41,\n",
       " 'cok': 42,\n",
       " 'kesinlikle': 43,\n",
       " 'telefon': 44,\n",
       " 'biraz': 45,\n",
       " 'hiç': 46,\n",
       " 'ulaştı': 47,\n",
       " 'memnun': 48,\n",
       " 'hem': 49,\n",
       " 'değil': 50,\n",
       " 'kullanışlı': 51,\n",
       " '3': 52,\n",
       " 'mükemmel': 53,\n",
       " 'oldu': 54,\n",
       " 'kullanıyorum': 55,\n",
       " 'önce': 56,\n",
       " 'sipariş': 57,\n",
       " 'tek': 58,\n",
       " 'her': 59,\n",
       " 'bence': 60,\n",
       " 'harika': 61,\n",
       " 'kalitesi': 62,\n",
       " 'bi': 63,\n",
       " 'ayrıca': 64,\n",
       " '5': 65,\n",
       " 'teşekkür': 66,\n",
       " 'fiyatı': 67,\n",
       " 'olması': 68,\n",
       " 'ne': 69,\n",
       " 'herkese': 70,\n",
       " 'bile': 71,\n",
       " 'uzun': 72,\n",
       " 'süper': 73,\n",
       " 'tam': 74,\n",
       " 'zaten': 75,\n",
       " 'fazla': 76,\n",
       " 'ilk': 77,\n",
       " 'o': 78,\n",
       " 'başarılı': 79,\n",
       " 'fakat': 80,\n",
       " 'memnunum': 81,\n",
       " 'ancak': 82,\n",
       " 'ediyorum': 83,\n",
       " 'şarj': 84,\n",
       " 'saat': 85,\n",
       " 'fiyatına': 86,\n",
       " 'oldukça': 87,\n",
       " 'hemen': 88,\n",
       " 'şekilde': 89,\n",
       " 'ses': 90,\n",
       " 'hepsi': 91,\n",
       " 'gerek': 92,\n",
       " 'rahat': 93,\n",
       " 'aynı': 94,\n",
       " '4': 95,\n",
       " 'şık': 96,\n",
       " 'verdim': 97,\n",
       " 'kolay': 98,\n",
       " 'diye': 99,\n",
       " 'ki': 100,\n",
       " 'sadece': 101,\n",
       " 'kaldım': 102,\n",
       " 'diğer': 103,\n",
       " 'büyük': 104,\n",
       " 'sorun': 105,\n",
       " 'alın': 106,\n",
       " 'burada': 107,\n",
       " 'kısa': 108,\n",
       " 'ürünün': 109,\n",
       " 'sorunsuz': 110,\n",
       " 'performans': 111,\n",
       " 'içinde': 112,\n",
       " 'olan': 113,\n",
       " 'günde': 114,\n",
       " 'olsun': 115,\n",
       " 'küçük': 116,\n",
       " 'urun': 117,\n",
       " '10': 118,\n",
       " 'benim': 119,\n",
       " 'başka': 120,\n",
       " 'iki': 121,\n",
       " 'olduğu': 122,\n",
       " 'teslimat': 123,\n",
       " 'com': 124,\n",
       " 'arkadaşlar': 125,\n",
       " 'sağlam': 126,\n",
       " 'oluyor': 127,\n",
       " 'teslim': 128,\n",
       " 'ettim': 129,\n",
       " 'zaman': 130,\n",
       " 'kalite': 131,\n",
       " 'almak': 132,\n",
       " 'az': 133,\n",
       " 'telefonu': 134,\n",
       " 'yeni': 135,\n",
       " 'cihaz': 136,\n",
       " 'marka': 137,\n",
       " 'son': 138,\n",
       " 'koku': 139,\n",
       " 'ise': 140,\n",
       " 'kullandım': 141,\n",
       " 'kokusu': 142,\n",
       " 'derim': 143,\n",
       " 'olduğunu': 144,\n",
       " 'özellikle': 145,\n",
       " 'beğendim': 146,\n",
       " 'sıkıntı': 147,\n",
       " 'ucuz': 148,\n",
       " 'rağmen': 149,\n",
       " 'geçti': 150,\n",
       " 'geliyor': 151,\n",
       " 'guzel': 152,\n",
       " 'bana': 153,\n",
       " 'ya': 154,\n",
       " 'ideal': 155,\n",
       " 'orjinal': 156,\n",
       " 'almıştım': 157,\n",
       " 'yeterli': 158,\n",
       " 'tane': 159,\n",
       " 'hediye': 160,\n",
       " 'sürede': 161,\n",
       " 'yani': 162,\n",
       " 'normal': 163,\n",
       " 'yaklaşık': 164,\n",
       " 'ediyor': 165,\n",
       " 'hafif': 166,\n",
       " 'bunu': 167,\n",
       " 'ekran': 168,\n",
       " 'aldığım': 169,\n",
       " 'veriyor': 170,\n",
       " '6': 171,\n",
       " 'yüksek': 172,\n",
       " 'tüm': 173,\n",
       " 'pişman': 174,\n",
       " 'tercih': 175,\n",
       " 'düşünmeden': 176,\n",
       " 'kötü': 177,\n",
       " 'düşünüyorum': 178,\n",
       " 'numara': 179,\n",
       " 'bi̇r': 180,\n",
       " 'süre': 181,\n",
       " 'kullanımı': 182,\n",
       " 'çıktı': 183,\n",
       " 'günü': 184,\n",
       " 'su': 185,\n",
       " 'adet': 186,\n",
       " 'şey': 187,\n",
       " 'hemde': 188,\n",
       " 'icin': 189,\n",
       " 'hizli': 190,\n",
       " 'çalışıyor': 191,\n",
       " 'ay': 192,\n",
       " 'hb': 193,\n",
       " 'hafta': 194,\n",
       " 'sesi': 195,\n",
       " 'alışveriş': 196,\n",
       " 'farklı': 197,\n",
       " 'kitap': 198,\n",
       " 'yine': 199,\n",
       " 'böyle': 200,\n",
       " 'zor': 201,\n",
       " 'alabilirsiniz': 202,\n",
       " 'hızı': 203,\n",
       " 'çünkü': 204,\n",
       " 'para': 205,\n",
       " 'ertesi': 206,\n",
       " 'bende': 207,\n",
       " 'kullanım': 208,\n",
       " 'sürekli': 209,\n",
       " 'duruyor': 210,\n",
       " 'aldim': 211,\n",
       " 'olur': 212,\n",
       " 'hoş': 213,\n",
       " 'artık': 214,\n",
       " 'yapıyor': 215,\n",
       " 'konusunda': 216,\n",
       " 'yorumlara': 217,\n",
       " 'gönderi': 218,\n",
       " 'olsa': 219,\n",
       " 'gücü': 220,\n",
       " 'şu': 221,\n",
       " 'vardı': 222,\n",
       " 'üründen': 223,\n",
       " 'malzeme': 224,\n",
       " 'biri': 225,\n",
       " 'pratik': 226,\n",
       " 'dışında': 227,\n",
       " 'defa': 228,\n",
       " 'kullandığım': 229,\n",
       " 'şimdi': 230,\n",
       " 'diş': 231,\n",
       " 'samsung': 232,\n",
       " 'onun': 233,\n",
       " 'bugün': 234,\n",
       " 'özelliği': 235,\n",
       " 'iş': 236,\n",
       " 'kurulumu': 237,\n",
       " 'tereddüt': 238,\n",
       " 'şarjı': 239,\n",
       " 'i̇lk': 240,\n",
       " '7': 241,\n",
       " 'ince': 242,\n",
       " 'gelen': 243,\n",
       " 'kullanmaya': 244,\n",
       " 'diyebilirim': 245,\n",
       " 'almayı': 246,\n",
       " 'pek': 247,\n",
       " 'aldık': 248,\n",
       " 'denedim': 249,\n",
       " '8': 250,\n",
       " 'tekrar': 251,\n",
       " 'çabuk': 252,\n",
       " 'karar': 253,\n",
       " 'kez': 254,\n",
       " 'sahip': 255,\n",
       " 'kendi': 256,\n",
       " 'basit': 257,\n",
       " 'dolayı': 258,\n",
       " 'derece': 259,\n",
       " 'veya': 260,\n",
       " 'kamera': 261,\n",
       " 'pil': 262,\n",
       " 'hiçbir': 263,\n",
       " 'öncelikle': 264,\n",
       " 'açısından': 265,\n",
       " 'iphone': 266,\n",
       " 'sonuç': 267,\n",
       " 'yanında': 268,\n",
       " 'sessiz': 269,\n",
       " 'pahalı': 270,\n",
       " 'işe': 271,\n",
       " 'gidiyor': 272,\n",
       " 'dan': 273,\n",
       " 'olmadı': 274,\n",
       " 'öyle': 275,\n",
       " 'tesekkurler': 276,\n",
       " 'bunun': 277,\n",
       " 'beni': 278,\n",
       " 'varsa': 279,\n",
       " 'yer': 280,\n",
       " 'gece': 281,\n",
       " 'zamanında': 282,\n",
       " 'yorum': 283,\n",
       " 'performansı': 284,\n",
       " 'parfüm': 285,\n",
       " 'evde': 286,\n",
       " 'belli': 287,\n",
       " 'eğer': 288,\n",
       " 'oyun': 289,\n",
       " 'ağır': 290,\n",
       " 'iyisi': 291,\n",
       " 'arada': 292,\n",
       " 'mutlaka': 293,\n",
       " 'zamanda': 294,\n",
       " 'usb': 295,\n",
       " 'ufak': 296,\n",
       " 'üzerinde': 297,\n",
       " 'hatta': 298,\n",
       " 'fark': 299,\n",
       " 'gönül': 300,\n",
       " 'paketleme': 301,\n",
       " 'eşim': 302,\n",
       " 'alacak': 303,\n",
       " '15': 304,\n",
       " 'gereken': 305,\n",
       " 'doğru': 306,\n",
       " 'eski': 307,\n",
       " 'herhangi': 308,\n",
       " 'aydır': 309,\n",
       " 'tl': 310,\n",
       " 'kalıcı': 311,\n",
       " 'rahatlıkla': 312,\n",
       " 'vs': 313,\n",
       " 'satın': 314,\n",
       " 'alınabilecek': 315,\n",
       " 'bundan': 316,\n",
       " 'farkı': 317,\n",
       " 'görüntü': 318,\n",
       " 'lazım': 319,\n",
       " 'gercekten': 320,\n",
       " 'şiddetle': 321,\n",
       " 'kullanmak': 322,\n",
       " 'kaçırmayın': 323,\n",
       " 'alırken': 324,\n",
       " 'kargoya': 325,\n",
       " 'yaşamadım': 326,\n",
       " 'mi': 327,\n",
       " 'yaptım': 328,\n",
       " 'prima': 329,\n",
       " 'birlikte': 330,\n",
       " 'gördüm': 331,\n",
       " 'gerekiyor': 332,\n",
       " 'telefonun': 333,\n",
       " 'ürünler': 334,\n",
       " 'ayrı': 335,\n",
       " 'önemli': 336,\n",
       " 'sayesinde': 337,\n",
       " 'bütün': 338,\n",
       " 'yıl': 339,\n",
       " 'gb': 340,\n",
       " 'alalı': 341,\n",
       " 'beklediğimden': 342,\n",
       " 'almaya': 343,\n",
       " 'yerde': 344,\n",
       " 'olmasına': 345,\n",
       " 'tv': 346,\n",
       " 'sabah': 347,\n",
       " 'devam': 348,\n",
       " 'kutu': 349,\n",
       " 'henüz': 350,\n",
       " 'falan': 351,\n",
       " 'sorunu': 352,\n",
       " 'tabi': 353,\n",
       " 'a': 354,\n",
       " '20': 355,\n",
       " 'bakarak': 356,\n",
       " 'sanırım': 357,\n",
       " 'hepsiburadaya': 358,\n",
       " 'kulaklık': 359,\n",
       " 'süresi': 360,\n",
       " 'hala': 361,\n",
       " 'muhteşem': 362,\n",
       " 'dikkat': 363,\n",
       " 'güvenilir': 364,\n",
       " 'rahatsız': 365,\n",
       " 'edilir': 366,\n",
       " 'çıkıyor': 367,\n",
       " 'alıp': 368,\n",
       " 'yüzden': 369,\n",
       " 'toz': 370,\n",
       " 'kere': 371,\n",
       " 'orijinal': 372,\n",
       " 'sağlıyor': 373,\n",
       " 'kamerası': 374,\n",
       " 'dün': 375,\n",
       " 'ürüne': 376,\n",
       " 'düşük': 377,\n",
       " 'spor': 378,\n",
       " 'i̇yi': 379,\n",
       " 'problem': 380,\n",
       " 'öneririm': 381,\n",
       " 'edildi': 382,\n",
       " 'plastik': 383,\n",
       " 'içerisinde': 384,\n",
       " 'makine': 385,\n",
       " 'beri': 386,\n",
       " 'fazlasıyla': 387,\n",
       " 'baya': 388,\n",
       " 'kullanımda': 389,\n",
       " '30': 390,\n",
       " 'tavsi̇ye': 391,\n",
       " 'an': 392,\n",
       " 'yalnız': 393,\n",
       " 'özellikleri': 394,\n",
       " 'on': 395,\n",
       " 'den': 396,\n",
       " 'satıcı': 397,\n",
       " 'ilgili': 398,\n",
       " 'genel': 399,\n",
       " 'oldum': 400,\n",
       " 'kaç': 401,\n",
       " 'etkili': 402,\n",
       " 'sıcak': 403,\n",
       " 'haftadır': 404,\n",
       " 'üstelik': 405,\n",
       " 'fiyatıda': 406,\n",
       " 'olmuş': 407,\n",
       " '24': 408,\n",
       " 'yada': 409,\n",
       " 'hep': 410,\n",
       " 'üst': 411,\n",
       " 'olabilir': 412,\n",
       " 'paket': 413,\n",
       " 'bazı': 414,\n",
       " 'almışım': 415,\n",
       " 'güçlü': 416,\n",
       " 'piyasada': 417,\n",
       " 'yerine': 418,\n",
       " 'arasında': 419,\n",
       " 'renk': 420,\n",
       " 'inanılmaz': 421,\n",
       " 'arkadaşlara': 422,\n",
       " 'paraya': 423,\n",
       " 'kurulum': 424,\n",
       " 'umarım': 425,\n",
       " 'sert': 426,\n",
       " 'kitabı': 427,\n",
       " 'ederi̇m': 428,\n",
       " 'olmuyor': 429,\n",
       " 'fena': 430,\n",
       " 'gitti': 431,\n",
       " 'servis': 432,\n",
       " 'altında': 433,\n",
       " 'üzerine': 434,\n",
       " 'nasıl': 435,\n",
       " 'birde': 436,\n",
       " 'ye': 437,\n",
       " 'gelince': 438,\n",
       " 'birşey': 439,\n",
       " 'note': 440,\n",
       " 'yorumları': 441,\n",
       " 'başladım': 442,\n",
       " 'olanlar': 443,\n",
       " 'ön': 444,\n",
       " '0': 445,\n",
       " 'dk': 446,\n",
       " 'üründe': 447,\n",
       " 'sanki': 448,\n",
       " 'kalitesini': 449,\n",
       " 'i̇yi̇': 450,\n",
       " 'sarj': 451,\n",
       " 'almadan': 452,\n",
       " 'etti': 453,\n",
       " 'alıyorum': 454,\n",
       " 'ev': 455,\n",
       " 'cihazı': 456,\n",
       " 'kullanıyoruz': 457,\n",
       " 'geç': 458,\n",
       " 'eşime': 459,\n",
       " 'görünce': 460,\n",
       " 'memnunuz': 461,\n",
       " 'yıldır': 462,\n",
       " 'edici': 463,\n",
       " 'bez': 464,\n",
       " 'arka': 465,\n",
       " 'saatte': 466,\n",
       " 'anda': 467,\n",
       " 'tamamen': 468,\n",
       " 'hizmet': 469,\n",
       " 'çekim': 470,\n",
       " 'herkes': 471,\n",
       " 'parmak': 472,\n",
       " 'akşam': 473,\n",
       " 'tutuyor': 474,\n",
       " 'geçen': 475,\n",
       " 'gore': 476,\n",
       " 'android': 477,\n",
       " 'elimize': 478,\n",
       " '12': 479,\n",
       " 'telefona': 480,\n",
       " 'temizlik': 481,\n",
       " 'görünüyor': 482,\n",
       " 'yumuşak': 483,\n",
       " 'kablo': 484,\n",
       " 'buradan': 485,\n",
       " '100': 486,\n",
       " 'kısmı': 487,\n",
       " 'size': 488,\n",
       " 'orta': 489,\n",
       " 'piyasadaki': 490,\n",
       " 'net': 491,\n",
       " 'hak': 492,\n",
       " 'yere': 493,\n",
       " 'günlük': 494,\n",
       " 'beğendi': 495,\n",
       " 'rahatlığıyla': 496,\n",
       " 'eder': 497,\n",
       " 'hız': 498,\n",
       " 'müzik': 499,\n",
       " 'kalın': 500,\n",
       " 'siyah': 501,\n",
       " 'urunu': 502,\n",
       " 'degil': 503,\n",
       " 'bedava': 504,\n",
       " 'istediğim': 505,\n",
       " 'oğlum': 506,\n",
       " 'saç': 507,\n",
       " 'güvenli': 508,\n",
       " 'kılıf': 509,\n",
       " 'onu': 510,\n",
       " 'yıldız': 511,\n",
       " 'yoksa': 512,\n",
       " 'çıkan': 513,\n",
       " 'hesaplı': 514,\n",
       " 'etmeden': 515,\n",
       " 'hava': 516,\n",
       " 'piyasaya': 517,\n",
       " 'kilo': 518,\n",
       " 'ışık': 519,\n",
       " 'neredeyse': 520,\n",
       " 'fotoğraf': 521,\n",
       " 'i̇çi̇n': 522,\n",
       " 'tşk': 523,\n",
       " 'belki': 524,\n",
       " 'olurdu': 525,\n",
       " 'kablosu': 526,\n",
       " 'bır': 527,\n",
       " 'mı': 528,\n",
       " 'gündür': 529,\n",
       " 'temiz': 530,\n",
       " 'garantili': 531,\n",
       " 'içine': 532,\n",
       " 'alınabilir': 533,\n",
       " 'herşey': 534,\n",
       " 'almanızı': 535,\n",
       " 'siparişi': 536,\n",
       " 'olmaz': 537,\n",
       " 'keşke': 538,\n",
       " 'kendini': 539,\n",
       " 'olacak': 540,\n",
       " 'yakın': 541,\n",
       " 'rengi': 542,\n",
       " 'gun': 543,\n",
       " 'süpürge': 544,\n",
       " 'traş': 545,\n",
       " 'çift': 546,\n",
       " 'şuan': 547,\n",
       " 'gönderim': 548,\n",
       " 'buna': 549,\n",
       " 'motor': 550,\n",
       " 'birkaç': 551,\n",
       " 'hoşuma': 552,\n",
       " 'tasarımı': 553,\n",
       " 'kaldık': 554,\n",
       " 'verdiğim': 555,\n",
       " 'hic': 556,\n",
       " 'değer': 557,\n",
       " 'yağ': 558,\n",
       " 'ekonomik': 559,\n",
       " 'dedim': 560,\n",
       " 'tatmin': 561,\n",
       " 'isteyenlere': 562,\n",
       " 'içinden': 563,\n",
       " 'araştırdım': 564,\n",
       " 'oda': 565,\n",
       " 'yıllardır': 566,\n",
       " 'mevcut': 567,\n",
       " 'kızım': 568,\n",
       " 'kalıyor': 569,\n",
       " 'yapmak': 570,\n",
       " 'buldum': 571,\n",
       " 'şimdilik': 572,\n",
       " 'yanı': 573,\n",
       " 'makina': 574,\n",
       " 'görüyor': 575,\n",
       " 'model': 576,\n",
       " 'kargoda': 577,\n",
       " 'kaldı': 578,\n",
       " '9': 579,\n",
       " 'üstünde': 580,\n",
       " 'avantaj': 581,\n",
       " 'sizi': 582,\n",
       " 'alet': 583,\n",
       " 'müthiş': 584,\n",
       " 'metal': 585,\n",
       " 'ürünleri': 586,\n",
       " 'mouse': 587,\n",
       " 'beraber': 588,\n",
       " 'bebek': 589,\n",
       " 'kullanıyordum': 590,\n",
       " 'geri': 591,\n",
       " 'ederiz': 592,\n",
       " 'başta': 593,\n",
       " 'makul': 594,\n",
       " 'olmazsınız': 595,\n",
       " 'apple': 596,\n",
       " 'yaptı': 597,\n",
       " 'okudum': 598,\n",
       " 'elimde': 599,\n",
       " 'görür': 600,\n",
       " 'olduğundan': 601,\n",
       " 'fiyatının': 602,\n",
       " 'açık': 603,\n",
       " 'üzerinden': 604,\n",
       " 'aşırı': 605,\n",
       " 'özellik': 606,\n",
       " 'e': 607,\n",
       " 'olanlara': 608,\n",
       " 'izi': 609,\n",
       " 'garanti': 610,\n",
       " 'film': 611,\n",
       " 'biz': 612,\n",
       " 'yavaş': 613,\n",
       " 'ucuza': 614,\n",
       " 'bişey': 615,\n",
       " 'tartışılmaz': 616,\n",
       " 'sene': 617,\n",
       " 'super': 618,\n",
       " 'site': 619,\n",
       " 'birçok': 620,\n",
       " 'ücretsiz': 621,\n",
       " 'sonunda': 622,\n",
       " 'ısınma': 623,\n",
       " 'saati': 624,\n",
       " 'batarya': 625,\n",
       " 'kapalı': 626,\n",
       " 'olumsuz': 627,\n",
       " 'alan': 628,\n",
       " 'hediyesi': 629,\n",
       " 'kullaniyorum': 630,\n",
       " 'yapmıyor': 631,\n",
       " 'eve': 632,\n",
       " 'evet': 633,\n",
       " 'önceki': 634,\n",
       " 'sık': 635,\n",
       " 'hakkını': 636,\n",
       " 'beklediğim': 637,\n",
       " 'kelimeyle': 638,\n",
       " 'beyaz': 639,\n",
       " 'zorunda': 640,\n",
       " 'üç': 641,\n",
       " 'kat': 642,\n",
       " 'telefonda': 643,\n",
       " 'tasarım': 644,\n",
       " 'dakika': 645,\n",
       " 'etmek': 646,\n",
       " 'uyumlu': 647,\n",
       " 'önceden': 648,\n",
       " 'olunca': 649,\n",
       " 'severek': 650,\n",
       " 'isteyenler': 651,\n",
       " 'diyorum': 652,\n",
       " 'çanta': 653,\n",
       " 'el': 654,\n",
       " 'istedim': 655,\n",
       " 'iyiki': 656,\n",
       " 'kullanın': 657,\n",
       " 'yoktu': 658,\n",
       " 'sıkıntısı': 659,\n",
       " 'ikinci': 660,\n",
       " 'yorumlarda': 661,\n",
       " 'çekiyor': 662,\n",
       " 'bilmiyorum': 663,\n",
       " 'kullanma': 664,\n",
       " 'araç': 665,\n",
       " 'edin': 666,\n",
       " 'görüntüsü': 667,\n",
       " 'firma': 668,\n",
       " 'alıyor': 669,\n",
       " 'hepsi̇burada': 670,\n",
       " 'alt': 671,\n",
       " 'olmadan': 672,\n",
       " 'bazen': 673,\n",
       " 'dayanıklı': 674,\n",
       " 'olmaması': 675,\n",
       " 'ona': 676,\n",
       " 'iade': 677,\n",
       " 'fiyatlı': 678,\n",
       " 'internet': 679,\n",
       " 'geniş': 680,\n",
       " 'philips': 681,\n",
       " 'koltuk': 682,\n",
       " 'elimdeydi': 683,\n",
       " 'kullanan': 684,\n",
       " 'yaparken': 685,\n",
       " 'derecede': 686,\n",
       " 'asla': 687,\n",
       " '16': 688,\n",
       " 'kalitede': 689,\n",
       " 'taktım': 690,\n",
       " 'resmen': 691,\n",
       " 'eden': 692,\n",
       " 'halde': 693,\n",
       " 'merhaba': 694,\n",
       " 'mukemmel': 695,\n",
       " 'hassas': 696,\n",
       " 'başladı': 697,\n",
       " 'zarar': 698,\n",
       " 'kalitesiz': 699,\n",
       " 'aylık': 700,\n",
       " 'açıkçası': 701,\n",
       " 'mutlu': 702,\n",
       " 'alin': 703,\n",
       " 'yeri': 704,\n",
       " 'ram': 705,\n",
       " 'neden': 706,\n",
       " 'eksiksiz': 707,\n",
       " 'paketlenmiş': 708,\n",
       " 'idi': 709,\n",
       " 'idare': 710,\n",
       " 'iyiydi': 711,\n",
       " 'olabilirdi': 712,\n",
       " 'yarıyor': 713,\n",
       " 'gerekli': 714,\n",
       " 'olduğum': 715,\n",
       " '50': 716,\n",
       " 'parfümü': 717,\n",
       " 'buradaya': 718,\n",
       " 'kelime': 719,\n",
       " 'herkesin': 720,\n",
       " 'olmasi': 721,\n",
       " 'ara': 722,\n",
       " 'verildi': 723,\n",
       " 'yoğun': 724,\n",
       " 'etkisi': 725,\n",
       " 'vermeye': 726,\n",
       " 'saçlarım': 727,\n",
       " 'siz': 728,\n",
       " 'kullanıyor': 729,\n",
       " 'b': 730,\n",
       " '40': 731,\n",
       " 'zamandır': 732,\n",
       " 'yapan': 733,\n",
       " 'olmayan': 734,\n",
       " 'yorumlar': 735,\n",
       " 'ayrica': 736,\n",
       " 'yinede': 737,\n",
       " 'kendim': 738,\n",
       " 'ulasti': 739,\n",
       " 'hafıza': 740,\n",
       " 'etmiyor': 741,\n",
       " 'almış': 742,\n",
       " 'yapılmış': 743,\n",
       " 'verdikten': 744,\n",
       " 'kendime': 745,\n",
       " 'yedek': 746,\n",
       " 'düşünenlere': 747,\n",
       " 'durum': 748,\n",
       " 'sonuçta': 749,\n",
       " 'yerden': 750,\n",
       " 'etmiyorum': 751,\n",
       " 'video': 752,\n",
       " 'çekiş': 753,\n",
       " 'cuma': 754,\n",
       " 'cam': 755,\n",
       " 'uygulama': 756,\n",
       " 'içi': 757,\n",
       " 'işi': 758,\n",
       " 'eksik': 759,\n",
       " 'ihtiyacı': 760,\n",
       " 'eksiği': 761,\n",
       " 'faydalı': 762,\n",
       " 'göz': 763,\n",
       " 'deneme': 764,\n",
       " 'isteyen': 765,\n",
       " 'acaba': 766,\n",
       " 'kısacası': 767,\n",
       " 'kullanabilirsiniz': 768,\n",
       " 'merak': 769,\n",
       " 'temizliyor': 770,\n",
       " 'ürünle': 771,\n",
       " 'rahatlığı': 772,\n",
       " 'p': 773,\n",
       " 'türkiye': 774,\n",
       " 'hepsiburadadan': 775,\n",
       " 'aldı': 776,\n",
       " 'görmedim': 777,\n",
       " 'test': 778,\n",
       " 'ana': 779,\n",
       " 'aldıktan': 780,\n",
       " 'aleti': 781,\n",
       " 'şimdiye': 782,\n",
       " 'yapıyorum': 783,\n",
       " 'olumlu': 784,\n",
       " 'hakkında': 785,\n",
       " 'piyasa': 786,\n",
       " 'ekranı': 787,\n",
       " 'mümkün': 788,\n",
       " 'kış': 789,\n",
       " 'siparis': 790,\n",
       " 'd': 791,\n",
       " 'malı': 792,\n",
       " 'elinize': 793,\n",
       " 'km': 794,\n",
       " 'gösteriyor': 795,\n",
       " 'haricinde': 796,\n",
       " 'donma': 797,\n",
       " 'denemek': 798,\n",
       " 'türlü': 799,\n",
       " 'i': 800,\n",
       " 'alacaklara': 801,\n",
       " 'elde': 802,\n",
       " 'dış': 803,\n",
       " 'dokunmatik': 804,\n",
       " 'gerçek': 805,\n",
       " 'tabiki': 806,\n",
       " 'ürünlere': 807,\n",
       " 'boyutu': 808,\n",
       " 'hissi': 809,\n",
       " 'söyleyebilirim': 810,\n",
       " 'cabası': 811,\n",
       " 'kaldim': 812,\n",
       " 'emiş': 813,\n",
       " 'kanal': 814,\n",
       " 'takip': 815,\n",
       " 'problemi': 816,\n",
       " 'tavsiyem': 817,\n",
       " 'kargolama': 818,\n",
       " 'aslında': 819,\n",
       " 'dahi': 820,\n",
       " 'yardımcı': 821,\n",
       " 'akıcı': 822,\n",
       " 'ütü': 823,\n",
       " 'konuda': 824,\n",
       " 'hayırlı': 825,\n",
       " 'değilim': 826,\n",
       " 'herkeze': 827,\n",
       " 'karşı': 828,\n",
       " 'markanın': 829,\n",
       " 'kutusu': 830,\n",
       " 'elektrik': 831,\n",
       " 'yaz': 832,\n",
       " 'yerli': 833,\n",
       " 'tavsıye': 834,\n",
       " 'emin': 835,\n",
       " 's': 836,\n",
       " 'lg': 837,\n",
       " 'once': 838,\n",
       " 'araba': 839,\n",
       " 'pazartesi': 840,\n",
       " 'f': 841,\n",
       " 'kullandıktan': 842,\n",
       " 'yatak': 843,\n",
       " 'zarif': 844,\n",
       " 'gelir': 845,\n",
       " 'beden': 846,\n",
       " 'özel': 847,\n",
       " 'ciddi': 848,\n",
       " 'kontrol': 849,\n",
       " 'olmak': 850,\n",
       " 'i̇ki': 851,\n",
       " 'zamanla': 852,\n",
       " 'fayda': 853,\n",
       " 'istiyorsanız': 854,\n",
       " 'bağlantı': 855,\n",
       " 'sıfır': 856,\n",
       " 'çıkmadı': 857,\n",
       " 'ayni': 858,\n",
       " 'parasını': 859,\n",
       " 'fön': 860,\n",
       " 'anladım': 861,\n",
       " 'düzgün': 862,\n",
       " 'olmadığı': 863,\n",
       " 'fiyatını': 864,\n",
       " 'kibar': 865,\n",
       " 'veren': 866,\n",
       " 'sağlıklı': 867,\n",
       " 'birisi': 868,\n",
       " 'soğuk': 869,\n",
       " 'montaj': 870,\n",
       " 'klasik': 871,\n",
       " 'parça': 872,\n",
       " 'yarım': 873,\n",
       " 'telefondan': 874,\n",
       " 'okuma': 875,\n",
       " 'makinesi': 876,\n",
       " 'verilen': 877,\n",
       " 'düzenli': 878,\n",
       " 'düşünmeyin': 879,\n",
       " 'kullanılabilir': 880,\n",
       " 'koruyucu': 881,\n",
       " 'anneme': 882,\n",
       " 'hale': 883,\n",
       " 'ömrü': 884,\n",
       " 'kalitesine': 885,\n",
       " 'bulmak': 886,\n",
       " 'kullanmadım': 887,\n",
       " 'saglam': 888,\n",
       " 'normalde': 889,\n",
       " 'cm': 890,\n",
       " 'xiaomi': 891,\n",
       " 'beklemeyin': 892,\n",
       " 'çoğu': 893,\n",
       " 'pili': 894,\n",
       " 'çocuk': 895,\n",
       " 'bakımından': 896,\n",
       " 'birebir': 897,\n",
       " 'yazma': 898,\n",
       " 'boyu': 899,\n",
       " 'hareket': 900,\n",
       " 'siteden': 901,\n",
       " 'cihazın': 902,\n",
       " 'led': 903,\n",
       " 'tahmin': 904,\n",
       " 'kapak': 905,\n",
       " 'bilgisayar': 906,\n",
       " 'ısınıyor': 907,\n",
       " 'eksi': 908,\n",
       " 'gelmesi': 909,\n",
       " 'kalmadı': 910,\n",
       " 'begendim': 911,\n",
       " 'kullanisli': 912,\n",
       " 'verip': 913,\n",
       " 'günden': 914,\n",
       " 'kaçmaz': 915,\n",
       " 'sürükleyici': 916,\n",
       " 'sonucu': 917,\n",
       " 'markası': 918,\n",
       " 'indirim': 919,\n",
       " 'oranı': 920,\n",
       " 'arkadaşım': 921,\n",
       " 'telefonum': 922,\n",
       " 'temizliği': 923,\n",
       " 'şarjlı': 924,\n",
       " 'kullanırken': 925,\n",
       " 'zayıf': 926,\n",
       " 'tesekkur': 927,\n",
       " 'çıkarıyor': 928,\n",
       " 'karşıladı': 929,\n",
       " 'sistemi': 930,\n",
       " 'akıllı': 931,\n",
       " 'ortalama': 932,\n",
       " 'direk': 933,\n",
       " 'alınır': 934,\n",
       " 'olsaydı': 935,\n",
       " 'arkadaslar': 936,\n",
       " 'profesyonel': 937,\n",
       " 'boşuna': 938,\n",
       " 'hd': 939,\n",
       " 'sony': 940,\n",
       " 'iç': 941,\n",
       " 'ekstra': 942,\n",
       " 'yi': 943,\n",
       " 'kuru': 944,\n",
       " 'sonrası': 945,\n",
       " 'almayın': 946,\n",
       " 'lik': 947,\n",
       " 'kusursuz': 948,\n",
       " 'başlık': 949,\n",
       " 'seviyede': 950,\n",
       " 'bluetooth': 951,\n",
       " 'kullanmıştım': 952,\n",
       " 'burda': 953,\n",
       " 'genelde': 954,\n",
       " 'kokuyu': 955,\n",
       " 'olacağını': 956,\n",
       " 'siparişim': 957,\n",
       " 'burdan': 958,\n",
       " 'kampanya': 959,\n",
       " 'nin': 960,\n",
       " 'olanı': 961,\n",
       " 'vestel': 962,\n",
       " 'alacağım': 963,\n",
       " 'tarafı': 964,\n",
       " 'insan': 965,\n",
       " 'artı': 966,\n",
       " 'paketi': 967,\n",
       " 'ayarı': 968,\n",
       " 'karşılıyor': 969,\n",
       " 'üstüne': 970,\n",
       " 'premium': 971,\n",
       " 'kalıcılığı': 972,\n",
       " 'eminim': 973,\n",
       " 'olup': 974,\n",
       " 'ürünlerden': 975,\n",
       " 'malzemesi': 976,\n",
       " 'mavi': 977,\n",
       " 'buradaki': 978,\n",
       " 'markalara': 979,\n",
       " 'parlak': 980,\n",
       " 'söz': 981,\n",
       " 'ergonomik': 982,\n",
       " 'yaptığım': 983,\n",
       " 'kendisi': 984,\n",
       " 'düşünen': 985,\n",
       " 'hızlıydı': 986,\n",
       " 'kasma': 987,\n",
       " 'fiyatta': 988,\n",
       " 'enerji': 989,\n",
       " 'kolayca': 990,\n",
       " 'yan': 991,\n",
       " 'pc': 992,\n",
       " '00': 993,\n",
       " 'bol': 994,\n",
       " 'kablosuz': 995,\n",
       " 'full': 996,\n",
       " 'işinizi': 997,\n",
       " 'modeli': 998,\n",
       " 'oturuyor': 999,\n",
       " 'kişi': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1e37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42276284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ürünü alalı 3 hafta kadar oldu. aralıksız kullanıyorum bilgisyarım sürekli açık durur ve ben günde yaklaşık 12 saat başındayım mousesu çok kullanırım. şimdiye kadar bir problem yaşamadım ve çok memnunum almak isteyenlere tavsiye ederim.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da51c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 341, 52, 194, 30, 54, 7992, 55, 209, 603, 7887, 3, 36, 114, 164, 479, 85, 1, 1682, 782, 30, 2, 380, 326, 3, 1, 81, 132, 562, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a60f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Kümesini Tokenleştirme\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01459342",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ed37f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.744703220162876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a6426a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e03f0a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21941"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6cf04bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Özellikle bu kısma yazıyorum iyice okuyunuz,cihazın hızı çok iyi.Isınma normal boyutlarda.Kamerası elinizi sabit tutarsanız ve gündüz çok net gece ise çok net çekmez.Görüntülü konuşma özelliği yok ancak uygulama ile olur,anten çekimi gayet iyi.Parmak izi okuyucusu gayet hızlı bazen tuşu silmenizi istiyor ve okuyamıyor kirden vs...Ön kamera da tatmin edici,çekim esnasında ekran beyaz ışık vererek flaş görevi görür.Batarya bana 1 hafta gidiyor sık kullanımda ise 2-3 gün gidiyor.Hızlı şarj 1 saatte doluyor , şekilleri ele oturuyor ve şık bir görüntü var.Telefonu aldığım gün gittim ve ilk girdiğim yerden ekran koruyucu ve kılıf buldum.Kulaklık sesi çok net ve yüksek ancak kendi hoparlörü biraz zayıf sesi.Ekrana bakarken açık kalma özelliği yok.Diğer akıllı cihaz özellikleri %90 ı bu cihazda mevcut.Güç tasarrufu 2 ayrı modu var ve çok başarılı çalışıyor.4gb ram var genelde yarısı boş kalıyor.Bir de yeni cihazların çoğu titreşimi az ve sesi de az çıkıyor.Bu cihaz da içine dahil...Bu cihazlar güncelleme almaz ve rom bulunmuyormuş.Benim için güncelleme sorun olmaz -cihaz parasına göre s serisi ile yarışıyor çünkü.Biraz metal olmasından dolayı elden kolay kaysada duruşu ve gösterişi iyidir.Çift flaşı var arkada.Kısaca şöyle ki bu fiyata bu ürün alınır.5 aydır kullanıyorum kasma donma felan zaten olmaz,bataryası iyi,şekli iyi,özellikler de iyi....En büyük kafa karıştıran soru şu ki hadi cihaz arıza yaptı veya düştü ekranı kırıldı.Bunun bir servisi var,ithalatçı garantisi de var.Cihazın adı sanı belli...Parça bulanmaz tamir olmaz derseniz size kalmış.Zaten normal bir cihazı da düşürseniz farkedermi?.Güncelleme almaz diyorlar bu konuda düşünebilirsiniz.S serisi cihazlarla hızını kıyaslarsınız ama güncelleme ile araya fark koymuşlar.İki katı fiyata satılan cihazla farkı olmasa zaten olmaz değil mi?Almayı düşünenler başka bir cihazla kıyas yapacaksa yine  7pro veya 9 baksınlar.C5 pro da biraz boyutu kısa ve kibar....Sonuçta ömürlük değil alın fazla düşünmeyin'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[21941]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e8d66ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5722535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597982726686571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3102a",
   "metadata": {},
   "source": [
    "### Tüm yorumların boyutunu eşitlemek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a9b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen = max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5ce7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pad = pad_sequences(x_test_tokens, maxlen = max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abe5638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194797, 59)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8693ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48700, 59)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f2755c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  19,  341,   52,  194,   30,   54, 7992,   55,  209,  603, 7887,\n",
       "          3,   36,  114,  164,  479,   85,    1, 1682,  782,   30,    2,\n",
       "        380,  326,    3,    1,   81,  132,  562,    9,   10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac9c761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,   19,  341,   52,  194,   30,\n",
       "         54, 7992,   55,  209,  603, 7887,    3,   36,  114,  164,  479,\n",
       "         85,    1, 1682,  782,   30,    2,  380,  326,    3,    1,   81,\n",
       "        132,  562,    9,   10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0efc6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b5281b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens) : \n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ede2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ürünü alalı 3 hafta kadar oldu. aralıksız kullanıyorum bilgisyarım sürekli açık durur ve ben günde yaklaşık 12 saat başındayım mousesu çok kullanırım. şimdiye kadar bir problem yaşamadım ve çok memnunum almak isteyenlere tavsiye ederim.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "633631fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ürünü alalı 3 hafta kadar oldu aralıksız kullanıyorum sürekli açık durur ve ben günde yaklaşık 12 saat çok kullanırım şimdiye kadar bir problem yaşamadım ve çok memnunum almak isteyenlere tavsiye ederim'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf2eb7",
   "metadata": {},
   "source": [
    "### SA:  Model Oluşturma ve Eğitme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44a61954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9d222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3b531de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim = num_words,\n",
    "                   output_dim = embedding_size,\n",
    "                   input_length = max_tokens,\n",
    "                   name = \"embedding_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7ea874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units = 16, return_sequences = True))\n",
    "model.add(GRU(units = 8, return_sequences = True))\n",
    "model.add(GRU(units = 4))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32be758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76447cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\",\n",
    "              optimizer = optimizer,\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67024a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_layer (Embedding  (None, 59, 50)            500000    \n",
      " )                                                               \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 59, 16)            3264      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 59, 8)             624       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 4)                 168       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504061 (1.92 MB)\n",
      "Trainable params: 504061 (1.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e54fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761/761 [==============================] - 53s 55ms/step - loss: 0.1795 - accuracy: 0.9536\n",
      "Epoch 2/5\n",
      "761/761 [==============================] - 38s 50ms/step - loss: 0.0918 - accuracy: 0.9714\n",
      "Epoch 3/5\n",
      "761/761 [==============================] - 36s 47ms/step - loss: 0.0694 - accuracy: 0.9790\n",
      "Epoch 4/5\n",
      "761/761 [==============================] - 37s 48ms/step - loss: 0.0539 - accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "761/761 [==============================] - 38s 50ms/step - loss: 0.0417 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d9f84f3c50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "model.fit(x_train_pad, y_train, epochs = 5, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bea2a23b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'str'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test_pad, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1102\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[0;32m   1108\u001b[0m         )\n\u001b[0;32m   1109\u001b[0m     )\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1115\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'str'>\"})"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a52191",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9b12d",
   "metadata": {},
   "source": [
    "### SA: Model Testi ve Kullanımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a61192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x = x_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4458cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p > 0.5 else 0.0 for p in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdd41216",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a80ce093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9344\\1826968042.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  incorrect = np.where(cls_pred != cls_true)\n"
     ]
    }
   ],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07d66481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4108868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = incorrect[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d66feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaliteli ürün köpeğim severek yedi. Golden Retriever. 1 günde kargo teslim edildi.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = x_test[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "393ba458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968141"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bdab1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaliteli ürün köpeğim severek yedi. Golden Retriever. 1 günde kargo teslim edildi.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_true[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9b23808",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"bu ürün çok iyi herkese tavsiye ederim\"\n",
    "text2 = \"kargo çok hızlı aynı gğn elime geçti\"\n",
    "text3 = \"büyük bir hayal kırıklığı yaşadım bu ürün bu markaya yakışmamış\"\n",
    "text4 = \"mükemmel\"\n",
    "text5 = \"tasarımı harika ancak kargo çok geç geldi ve ürün açılmıştı tavsiye etmem\"\n",
    "text6 = \"hiç resimde gösterildiği gibi değil\"\n",
    "text7 = \"kötü yorumlar gözümü korkutmuştu ancak hiçbir sorun yaşamadım teşekkürler\"\n",
    "text8 = \"hiç bu kadar kötü bir satıcıya denk gelmemiştim ürünü geri iade ediyorum \"\n",
    "text9 = \"tam bir fiyat performans ürünü\"\n",
    "text10 = \"beklediğim gibi çıkmadı\"\n",
    "\n",
    "texts = [text1, text2, text3, text4, text5, text6, text7, text8, text9, text10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53594d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d86d9e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 59)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pad = pad_sequences(tokens, maxlen = max_tokens)\n",
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51b2a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.997591  ],\n",
       "       [0.99428743],\n",
       "       [0.01839171],\n",
       "       [0.9960493 ],\n",
       "       [0.02380058],\n",
       "       [0.03118844],\n",
       "       [0.99556655],\n",
       "       [0.01161588],\n",
       "       [0.9968345 ],\n",
       "       [0.08763785]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tokens_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeae79d",
   "metadata": {},
   "source": [
    "### Makine Çevirisi (seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01cd3e",
   "metadata": {},
   "source": [
    "#### 1. seq2seq ile makine çevirisi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053234b9",
   "metadata": {},
   "source": [
    "#### Neural Machine Translation (NMT)\n",
    "Çeviriyi yapabilmek için uçtan uca eğitebileceğimiz büyükçe tek bir yapay sinir ağı oluşturmaya neural machine translation denir.\n",
    "\n",
    "Input text >>> ENCODER >>> [-0.1, 0.3, 0.2] >>> DECODER >>> Output text\n",
    "\n",
    "Encoder (one to many): Input' a göre tek bir vektör oluştur.\n",
    "\n",
    "Decoder (many to one): Vektöre göre sequence oluştur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348eaae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b634d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5305651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d416e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7d5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194943b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
